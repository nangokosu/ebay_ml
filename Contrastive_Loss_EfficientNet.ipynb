{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Contrastive Loss EfficientNet",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nangokosu/ebay_ml/blob/main/Contrastive_Loss_EfficientNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "902qcJxt1scq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f135ea74-dbd1-49a3-9cfb-0b1b5d1b25f1"
      },
      "source": [
        "%tensorflow_version 2.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.2`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf_hhZwLh7vE",
        "outputId": "3053437d-4215-42c5-8d5f-9c8d4d4887c8"
      },
      "source": [
        "!pip install efficientnet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting efficientnet\n",
            "  Downloading https://files.pythonhosted.org/packages/53/97/84f88e581d6ac86dcf1ab347c497c4c568c38784e3a2bd659b96912ab793/efficientnet-1.1.1-py3-none-any.whl\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet) (0.16.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.19.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.5)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (7.0.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.3.1)\n",
            "Installing collected packages: keras-applications, efficientnet\n",
            "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nUlMcbf3FvS"
      },
      "source": [
        "import keras\n",
        "from keras.layers import *\n",
        "import numpy as np\n",
        "import tensorflow_addons as tfa\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from skimage import color,data,transform,filters,util,restoration\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "import efficientnet.keras as efn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnwLDO645CQF"
      },
      "source": [
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sum_square, K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj8X7haD5E4z"
      },
      "source": [
        "def contrastive_loss(y_true, y_pred):\n",
        "    '''Contrastive loss from Hadsell-et-al.'06\n",
        "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
        "    '''\n",
        "    margin = 0\n",
        "    y_pred = tf.convert_to_tensor(y_pred)\n",
        "    y_true = tf.dtypes.cast(y_true, y_pred.dtype)\n",
        "    square_pred = K.square(y_pred)\n",
        "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
        "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWbWA39B5PHF"
      },
      "source": [
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coFD1-lI4kM_"
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "def squeeze_excite_block(tensor, ratio=16):\n",
        "    init = tensor\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    filters = init.shape[channel_axis]\n",
        "    se_shape = (1, 1, filters)\n",
        "    se = GlobalAveragePooling2D()(init)\n",
        "    se = Reshape(se_shape)(se)\n",
        "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        se = Permute((3, 1, 2))(se)\n",
        "    x = Multiply()([init, se])\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwca3LU749Rg"
      },
      "source": [
        "def create_encoder(input_shape):\n",
        "  inputs=Input(shape=input_shape)\n",
        "  enet=efn.EfficientNetB2(include_top=False,weights='imagenet',input_tensor=inputs,pooling=None)\n",
        "  enet.trainable=False\n",
        "  outputs=squeeze_excite_block(enet.output,ratio=16)\n",
        "  outputs=GlobalAveragePooling2D()(outputs)\n",
        "  outputs=Dropout(0.2)(outputs)\n",
        "  outputs=Dense(120,activation=\"relu\")(outputs)\n",
        "  outputs=Dense(50,use_bias=False)(outputs)\n",
        "  #outputs=BatchNormalization()(outputs)\n",
        "  model = Model(\n",
        "      inputs=inputs, outputs=outputs, name='encoder'\n",
        "    )\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BmRL3Ea5eiV"
      },
      "source": [
        "def euclid_process(encoded_a,encoded_b):\n",
        "  distance = Lambda(euclidean_distance,output_shape=eucl_dist_output_shape)([encoded_a, encoded_b])\n",
        "  return distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_4j3_fl5X1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bffc5aaa-3918-4be5-ef40-893780ed6f95"
      },
      "source": [
        "shape=(32,32,3)\n",
        "input_1=Input(shape=(32,32,3))\n",
        "input_2=Input(shape=(32,32,3))\n",
        "encoder=create_encoder(shape)\n",
        "encoded_1=encoder(input_1)\n",
        "encoded_2=encoder(input_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b2_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
            "31940608/31936256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks_dUui-UEZ0"
      },
      "source": [
        "# ONLY APPLY IF RETRAINING\n",
        "# encoder=tf.keras.models.load_model('/content/drive/Shareddrives/eBay ML/contrastive_efficientnet_encoder')\n",
        "# for layer in encoder.layers[:-11]:\n",
        "#  layer.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sruz_5J6UCkD"
      },
      "source": [
        "encoded_1=encoder(input_1)\n",
        "encoded_2=encoder(input_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXoQMrLh2EWO"
      },
      "source": [
        "normalize_1=Lambda(lambda x: K.l2_normalize(x, axis=1))(encoded_1)\n",
        "normalize_2=Lambda(lambda x: K.l2_normalize(x, axis=1))(encoded_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkDjMXKi5imR"
      },
      "source": [
        "euclid_dist=euclid_process(normalize_1,normalize_2)\n",
        "euclid_model=Model([input_1,input_2],euclid_dist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v51n8SiK54Xe"
      },
      "source": [
        "lrplateau1=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.20,patience=8)\n",
        "modelCheckpoint=tf.keras.callbacks.ModelCheckpoint('/content/drive/Shareddrives/eBay ML/contrastive_efficientNet',save_best_only=True)\n",
        "early_stop=tf.keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Fuj8Ugfiamc"
      },
      "source": [
        "loss=tfa.losses.ContrastiveLoss(margin=2**0.5)\n",
        "euclid_model.compile(optimizer=\"Adam\",loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjQqvsrx6Ah9"
      },
      "source": [
        "df = pd.read_pickle(\"/content/drive/Shareddrives/eBay ML/normalized_df_pairs_balanced.pkl\")\n",
        "length = df.shape[0]\n",
        "df = df.iloc[2*length // 4:3*length // 4]\n",
        "df[\"similarity2\"]=df.similarity.apply(lambda x:0 if x==-1 else 1).astype('int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqfIGEoTiin7",
        "outputId": "6cef8f2e-2034-44c5-bdcc-f7a7b618c02c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVLqzDPr6Nti"
      },
      "source": [
        "image_1=efn.preprocess_input(np.stack(df[\"image_1\"]))\n",
        "image_2=efn.preprocess_input(np.stack(df[\"image_2\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNpeR5qP6QPN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ff4ac13-4c7a-4ac1-a1d1-782acade169a"
      },
      "source": [
        "euclid_model.fit([image_1,image_2],df.similarity2,callbacks=[lrplateau1,modelCheckpoint,early_stop],epochs=50,validation_split=0.10,batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1387/1387 [==============================] - 399s 276ms/step - loss: 0.3956 - val_loss: 0.4390\n",
            "INFO:tensorflow:Assets written to: /content/drive/Shareddrives/eBay ML/contrastive_efficientNet/assets\n",
            "Epoch 2/50\n",
            "1387/1387 [==============================] - 374s 270ms/step - loss: 0.3711 - val_loss: 0.4321\n",
            "INFO:tensorflow:Assets written to: /content/drive/Shareddrives/eBay ML/contrastive_efficientNet/assets\n",
            "Epoch 3/50\n",
            "1387/1387 [==============================] - 371s 268ms/step - loss: 0.3631 - val_loss: 0.4302\n",
            "INFO:tensorflow:Assets written to: /content/drive/Shareddrives/eBay ML/contrastive_efficientNet/assets\n",
            "Epoch 4/50\n",
            "1387/1387 [==============================] - 356s 257ms/step - loss: 0.3553 - val_loss: 0.4299\n",
            "INFO:tensorflow:Assets written to: /content/drive/Shareddrives/eBay ML/contrastive_efficientNet/assets\n",
            "Epoch 5/50\n",
            "1387/1387 [==============================] - 353s 255ms/step - loss: 0.3510 - val_loss: 0.4309\n",
            "Epoch 6/50\n",
            "1387/1387 [==============================] - 357s 257ms/step - loss: 0.3528 - val_loss: 0.4260\n",
            "INFO:tensorflow:Assets written to: /content/drive/Shareddrives/eBay ML/contrastive_efficientNet/assets\n",
            "Epoch 7/50\n",
            "1387/1387 [==============================] - 358s 258ms/step - loss: 0.3516 - val_loss: 0.4334\n",
            "Epoch 8/50\n",
            "1387/1387 [==============================] - 356s 257ms/step - loss: 0.3532 - val_loss: 0.4276\n",
            "Epoch 9/50\n",
            "1387/1387 [==============================] - 358s 258ms/step - loss: 0.3521 - val_loss: 0.4232\n",
            "INFO:tensorflow:Assets written to: /content/drive/Shareddrives/eBay ML/contrastive_efficientNet/assets\n",
            "Epoch 10/50\n",
            "1387/1387 [==============================] - 357s 257ms/step - loss: 0.3477 - val_loss: 0.4254\n",
            "Epoch 11/50\n",
            "1387/1387 [==============================] - 354s 255ms/step - loss: 0.3470 - val_loss: 0.4272\n",
            "Epoch 12/50\n",
            "1387/1387 [==============================] - 356s 257ms/step - loss: 0.3469 - val_loss: 0.4245\n",
            "Epoch 13/50\n",
            "1387/1387 [==============================] - 356s 256ms/step - loss: 0.3450 - val_loss: 0.4210\n",
            "INFO:tensorflow:Assets written to: /content/drive/Shareddrives/eBay ML/contrastive_efficientNet/assets\n",
            "Epoch 14/50\n",
            "1387/1387 [==============================] - 359s 259ms/step - loss: 0.3449 - val_loss: 0.4214\n",
            "Epoch 15/50\n",
            "1387/1387 [==============================] - 355s 256ms/step - loss: 0.3441 - val_loss: 0.4222\n",
            "Epoch 16/50\n",
            "1387/1387 [==============================] - 358s 258ms/step - loss: 0.3430 - val_loss: 0.4248\n",
            "Epoch 17/50\n",
            "1387/1387 [==============================] - 359s 259ms/step - loss: 0.3439 - val_loss: 0.4214\n",
            "Epoch 18/50\n",
            "1387/1387 [==============================] - 357s 257ms/step - loss: 0.3435 - val_loss: 0.4244\n",
            "Epoch 19/50\n",
            "1387/1387 [==============================] - 360s 259ms/step - loss: 0.3401 - val_loss: 0.4232\n",
            "Epoch 20/50\n",
            "1387/1387 [==============================] - 359s 259ms/step - loss: 0.3441 - val_loss: 0.4206\n",
            "INFO:tensorflow:Assets written to: /content/drive/Shareddrives/eBay ML/contrastive_efficientNet/assets\n",
            "Epoch 21/50\n",
            "1387/1387 [==============================] - 357s 258ms/step - loss: 0.3395 - val_loss: 0.4211\n",
            "Epoch 22/50\n",
            "1387/1387 [==============================] - 359s 259ms/step - loss: 0.3386 - val_loss: 0.4214\n",
            "Epoch 23/50\n",
            "1387/1387 [==============================] - 355s 256ms/step - loss: 0.3412 - val_loss: 0.4229\n",
            "Epoch 24/50\n",
            "1387/1387 [==============================] - 357s 258ms/step - loss: 0.3365 - val_loss: 0.4232\n",
            "Epoch 25/50\n",
            "1387/1387 [==============================] - 357s 257ms/step - loss: 0.3384 - val_loss: 0.4224\n",
            "Epoch 26/50\n",
            "1387/1387 [==============================] - 359s 259ms/step - loss: 0.3372 - val_loss: 0.4199\n",
            "INFO:tensorflow:Assets written to: /content/drive/Shareddrives/eBay ML/contrastive_efficientNet/assets\n",
            "Epoch 27/50\n",
            "1387/1387 [==============================] - 357s 258ms/step - loss: 0.3395 - val_loss: 0.4193\n",
            "INFO:tensorflow:Assets written to: /content/drive/Shareddrives/eBay ML/contrastive_efficientNet/assets\n",
            "Epoch 28/50\n",
            "1387/1387 [==============================] - 357s 257ms/step - loss: 0.3341 - val_loss: 0.4194\n",
            "Epoch 29/50\n",
            "1387/1387 [==============================] - 358s 258ms/step - loss: 0.3377 - val_loss: 0.4189\n",
            "INFO:tensorflow:Assets written to: /content/drive/Shareddrives/eBay ML/contrastive_efficientNet/assets\n",
            "Epoch 30/50\n",
            "1387/1387 [==============================] - 358s 258ms/step - loss: 0.3372 - val_loss: 0.4185\n",
            "INFO:tensorflow:Assets written to: /content/drive/Shareddrives/eBay ML/contrastive_efficientNet/assets\n",
            "Epoch 31/50\n",
            "1387/1387 [==============================] - 356s 257ms/step - loss: 0.3345 - val_loss: 0.4184\n",
            "INFO:tensorflow:Assets written to: /content/drive/Shareddrives/eBay ML/contrastive_efficientNet/assets\n",
            "Epoch 32/50\n",
            "1387/1387 [==============================] - 360s 260ms/step - loss: 0.3364 - val_loss: 0.4226\n",
            "Epoch 33/50\n",
            "1387/1387 [==============================] - 361s 260ms/step - loss: 0.3358 - val_loss: 0.4180\n",
            "INFO:tensorflow:Assets written to: /content/drive/Shareddrives/eBay ML/contrastive_efficientNet/assets\n",
            "Epoch 34/50\n",
            "1387/1387 [==============================] - 354s 255ms/step - loss: 0.3357 - val_loss: 0.4189\n",
            "Epoch 35/50\n",
            "1387/1387 [==============================] - 360s 259ms/step - loss: 0.3338 - val_loss: 0.4182\n",
            "Epoch 36/50\n",
            "1387/1387 [==============================] - 359s 259ms/step - loss: 0.3345 - val_loss: 0.4191\n",
            "Epoch 37/50\n",
            "1387/1387 [==============================] - 360s 259ms/step - loss: 0.3343 - val_loss: 0.4219\n",
            "Epoch 38/50\n",
            "1387/1387 [==============================] - 360s 260ms/step - loss: 0.3336 - val_loss: 0.4191\n",
            "Epoch 39/50\n",
            "1387/1387 [==============================] - 358s 258ms/step - loss: 0.3348 - val_loss: 0.4186\n",
            "Epoch 40/50\n",
            "1387/1387 [==============================] - 357s 257ms/step - loss: 0.3336 - val_loss: 0.4184\n",
            "Epoch 41/50\n",
            "1387/1387 [==============================] - 355s 256ms/step - loss: 0.3329 - val_loss: 0.4173\n",
            "INFO:tensorflow:Assets written to: /content/drive/Shareddrives/eBay ML/contrastive_efficientNet/assets\n",
            "Epoch 42/50\n",
            "1387/1387 [==============================] - 357s 258ms/step - loss: 0.3319 - val_loss: 0.4195\n",
            "Epoch 43/50\n",
            "1387/1387 [==============================] - 357s 257ms/step - loss: 0.3331 - val_loss: 0.4166\n",
            "INFO:tensorflow:Assets written to: /content/drive/Shareddrives/eBay ML/contrastive_efficientNet/assets\n",
            "Epoch 44/50\n",
            "1387/1387 [==============================] - 356s 257ms/step - loss: 0.3304 - val_loss: 0.4190\n",
            "Epoch 45/50\n",
            "1387/1387 [==============================] - 359s 259ms/step - loss: 0.3323 - val_loss: 0.4164\n",
            "INFO:tensorflow:Assets written to: /content/drive/Shareddrives/eBay ML/contrastive_efficientNet/assets\n",
            "Epoch 46/50\n",
            "1387/1387 [==============================] - 358s 258ms/step - loss: 0.3308 - val_loss: 0.4181\n",
            "Epoch 47/50\n",
            "1387/1387 [==============================] - 361s 261ms/step - loss: 0.3324 - val_loss: 0.4163\n",
            "INFO:tensorflow:Assets written to: /content/drive/Shareddrives/eBay ML/contrastive_efficientNet/assets\n",
            "Epoch 48/50\n",
            "1387/1387 [==============================] - 360s 260ms/step - loss: 0.3311 - val_loss: 0.4180\n",
            "Epoch 49/50\n",
            "1387/1387 [==============================] - 358s 258ms/step - loss: 0.3267 - val_loss: 0.4163\n",
            "INFO:tensorflow:Assets written to: /content/drive/Shareddrives/eBay ML/contrastive_efficientNet/assets\n",
            "Epoch 50/50\n",
            "1387/1387 [==============================] - 357s 258ms/step - loss: 0.3317 - val_loss: 0.4173\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f867f531f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azr6G2686S2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6b1db90-189b-484a-fb33-5864af700000"
      },
      "source": [
        "tf.keras.models.save_model(encoder,\"/content/drive/Shareddrives/eBay ML/contrastive_efficientnet_encoder\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/Shareddrives/eBay ML/contrastive_efficientnet_encoder/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}